---
title: "Homework 1"
author: "Chen Zhang"
date: "Sep. 4, 2018"
output: word_document
---

Read and learn Chapter 1-2
Read and Learn Lecture Notes R functions, R Programming
Read and Lean R Markdown and Knitr
Problems 8, 9 P.121-122


8. This question involves the use of simple linear regression on the Auto
data set.
a. 1)placed Auto.csv to data folder in the working directory
2)read the data in R and check the data with summary(). Which variables are numeric and which variables are categorical?
3) horsepower should be numeric but read as categorical. Check the data set and find why.
4) If missing values are coded as ? in csv file how can we read it as missing value? Use na.string option to read it as missing value. Get help file using ?read.csv 

```{r}
auto_1 <- read.csv("Auto.csv", sep=",", header = TRUE)
attach(auto_1)
summary(auto_1)
class(horsepower);class(name)
```
_2)mpg,cylinders,displacement,weight,acceleration,year,origin are numeric. horsepower (Beacuse of some missing values) and name are categorical._

_3) Because of some missing data in horsepower, which use "?" to substitute missing value. In read.csv commend, the default character of missing value is "NA". Therefore, R couldn't cognize "?" as missing value._
```{r}
auto <- read.csv("Auto.csv",na.strings = "?",header=TRUE)
attach(auto)
summary(auto)
```

(b) Use the lm() function to perform a simple linear regression with
mpg as the response and horsepower as the predictor. Use the
summary() function to print the results. Comment on the output.

```{r}
auto_lm = lm(mpg~horsepower, data=auto)
attach(auto_lm)
summary(auto_lm)
```

i. Is there a relationship between the predictor and the response?

_Yes, there is a negitive relationalship between the predictor and the response. And that is a liner regression and p-value < 0.05,which means beta is not zero._

ii. How strong is the relationship between the predictor and the response?

_MSE =4.906,which is kind of small. We can see the R square is 0.6059, which implies that 60 percent of Y can be explained by X._
```{r}
cor_auto = cor(mpg,horsepower, use="complete.obs")
cor_auto
```

_What's more, we could calculate the correlation between response and predictor,which is -0.7784.Therefore, the relationship is kind of strong._


iii. Is the relationship between the predictor and the response
positive or negative? 

_Because the coefficent is -0.1578,which implies the relationship between the predictor and the response are negative. In other words, horsepower increase 1 unit, the mpg will decrease 0.1578 unit. _

iv. What is the predicted mpg associated with a horsepower of
98? What are the associated 95% confidence and prediction
intervals? 

```{r, echo=TRUE}
library(utils)
#confidence
predict(auto_lm,data.frame(horsepower=98),interval ="confidence")
#prediction
predict(auto_lm,data.frame(horsepower=98),interval ="prediction")
```
_the 95 % confidence interval associated with a horsepower value of 98 is (23.97, 24.96), and the 95 % prediction interval is (14.80, 34.12)_

(c) Plot the response and the predictor. Use the abline() function to display the least squares regression line. Use plot option to make the size of plot not large.
```{r, echo=TRUE,fig.height=3,fig.width=4}
plot(horsepower,mpg,xlab ="horsepower",ylab = "mpg")
abline(auto_lm,col="red")
```

(c) Use the plot() function to produce diagnostic plots of the least squares regression fit. Comment on any problems you see with the fit.Use par(mfrow=c(2,2)) to make plot small. 

```{r, echo=TRUE}
par(mfrow=c(2,2))
plot(auto_lm)
```

_Plot 1: Residuals vs Fitted:A linear regression of mpg on horsepower, the pattern is U shape, which means a strong pattern in the residuals indicates non-linearity in the auto data._
_Plot 2: Normal Q-Q: the residual is normally distributed, becuase it is a stright line(almost).The residual follows the line except for observation #323,330 and 334._
_plot 3: Scale-Location:it should look random and no pattern. The slope of red line goes up since the residuals spread wider and wider. It also has outliers, which are observation 334,323 and 330. In this book, we can also use residuals and rstudent function to plot the fitted value against residuals. heteroscedasticity is not obvious, residuals does not tend to increase with the fitted values,in other wards, autocorrelation is not obvious._
```{r,fig.height=3,fig.width=6}
par(mfrow=c(1,2))
plot(predict(auto_lm),residuals(auto_lm))
plot(predict(auto_lm),rstudent(auto_lm))
```

_plot4: Residual vs Leverage:The plot identifies the influential observation as #117. In this book, we can also use hatvalues() function to find the observation. If we exculde 117th and 116th case from this analysis, the regression result maybe alter a lot._
```{r}
which.max(hatvalues (auto_lm))
```


9. This question involves the use of multiple linear regression on the Auto data set.

(a) Produce a scatterplot matrix which includes all of the numeric variables in the data set. ?pairs. use pch="." option to plot points smaller. 

```{r, echo=TRUE}
pairs(auto,pch=".")
```

(b) Compute the matrix of correlations between the variables using the function cor(). You will need to exclude the name variable,which is qualitative.

```{r, echo=TRUE}
cor(auto[1:8],use="complete.obs")
```

(c) Use the lm() function to perform a multiple linear regression with mpg as the response and all other variables except name as the predictors. Use the summary() function to print the results.Comment on the output. First, we need to change the origin variable as a factor variable. origin of car (1. American, 2. European, 3. Japanese).Use function as.factor().

```{r, echo=TRUE}
#change the origin variables as a factor variables.
origin <- as.factor(auto$origin)
auto$origin[auto$origin =="1"] <- "American"
auto$origin[auto$origin =="2"] <- "European"
auto$origin[auto$origin =="3"] <- "Japanese"

auto_mulm <- lm(mpg~.-name,data=auto)
summary(auto_mulm)
```



i. Is there a relationship between the predictors and the response? 

_With respect to the multiple regression, we need to check the F-statistic. F-statistic is greater than 1. What's more the associated p-value < 0.05. Therefore, there is relationship between the prodictors and the response_.

ii. Which predictors appear to have a statistically significant
relationship to the response? 

_We could look at the individual p-values ,but if predictors are large,we are likely to make some false discoveries.Accoring to the individual p-value, it should be year, origin,and weight appear to have statistically significant realationship to the response. _.

```{r}
test <- anova(auto_mulm)
test
```

_We could also use F-value to see which predictors appear to have significant relationship with mpg. According to the regression result, all predictors except acceleration appear to have strong relationship with mpg._

iii. What does the coefficient for the year variable suggest? 

_When year increase one unit, then the mpg will increase 0.78 unit._

(d) Use the plot() function to produce diagnostic plots of the linear regression fit. Comment on any problems you see with the fit.

```{r, echo=TRUE}
par(mfrow=c(2,2))
plot(auto_mulm)
```

Do the residual plots suggest any unusually large outliers? Does
the leverage plot identify any observations with unusually high
leverage? 

_The residual plots suggest unusual large outliers when the fitted value is greater than 20, the observations spread wider and wider and deviate from the red line. We can tell from the plot4 that there are usually observation which is 14.We can use code to examine if it is correct._
```{r}
which.max(hatvalues (auto_mulm))
```

_plot 1: Fitted values vs Residuals, it seems like there is no pattern, which shows there is liner relationship between predictors and response._
_plot2: Normal Q-Q,the residual is not normally distributed._
_plot3: Scale-Location:it becomes wider and wider,hence it has a little bit heteroscedasticity.It also has outliers that we can obtain from the graph which are 323 and 327. _

(e) Use mpg~.^2 to fit linear regression models with
interaction effects. Do any interactions appear to be statistically
significant?

```{r, echo=TRUE}
auto_fit <- lm(mpg~ (cylinders+displacement+horsepower+weight+acceleration+year+origin)^2,data=auto)
summary(auto_fit)
```
_based on the individual p-value, acceleration:originEuropean, cylinders:acceleration,acceleration:year, acceleration:originJapanese, year:originEuropean,and year:originJapanese appears to be statistically significant._

**I use {r, echo=TRUE,fig.height=3,fig.width=4} to chenge the size of the graph. **
